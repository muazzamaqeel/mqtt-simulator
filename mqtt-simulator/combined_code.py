# Collected Files:
# - main.py
# - sensor_data_pb2.py
# - simulator.py
# - topic.py
# - utils.py
# - broker_settings.py
# - client_settings.py
# - __init__.py
# - topic_data.py
# - topic_data_bool.py
# - topic_data_math_expression.py
# - topic_data_number.py
# - topic_data_raw_value.py
# - __init__.py
# Total files collected: 14

:
    settings_file = Path(arg)
    if not settings_file.is_file():
        return parser.error(f"argument -f/--file: can't open '{arg}'")
    return settings_file


def compile_proto():
    proto_file = "sensor_data.proto"
    output_file = "sensor_data_pb2.py"

    if not os.path.exists(output_file) or os.path.getmtime(proto_file) > os.path.getmtime(output_file):
        print("Compiling Protobuf file using grpcio-tools...")
        result = protoc.main((
            '',
            f'--python_out=.',
            proto_file,
        ))
        if result != 0:
            print("Error compiling Protobuf file.")
            exit(1)
        else:
            print("Protobuf file compiled successfully.")

# Compile the Protobuf file if needed
compile_proto()

# Parse settings file argument
parser = argparse.ArgumentParser()
parser.add_argument('-f', '--file', dest='settings_file', type=lambda x: is_valid_file(parser, x), help='settings file', default=default_settings())
args = parser.parse_args()

# Initialize and run the simulator
simulator = Simulator(args.settings_file)
simulator.run()

# --- End of main.py ---


# --- Start of sensor_data_pb2.py ---
# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# NO CHECKED-IN PROTOBUF GENCODE
# source: sensor_data.proto
# Protobuf Python Version: 5.27.2
"""Generated protocol buffer code."""
from google.protobuf import descriptor as _descriptor
from google.protobuf import descriptor_pool as _descriptor_pool
from google.protobuf import runtime_version as _runtime_version
from google.protobuf import symbol_database as _symbol_database
from google.protobuf.internal import builder as _builder
_runtime_version.ValidateProtobufRuntimeVersion(
    _runtime_version.Domain.PUBLIC,
    5,
    27,
    2,
    '',
    'sensor_data.proto'
)
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()




DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n\x11sensor_data.proto\x12\x06Protos\"\xaf\x01\n\nSensorData\x12\x13\n\x0bpacifier_id\x18\x01 \x01(\t\x12\x13\n\x0bsensor_type\x18\x02 \x01(\t\x12\x14\n\x0csensor_group\x18\x03 \x01(\t\x12\x31\n\x08\x64\x61ta_map\x18\x04 \x03(\x0b\x32\x1f.Protos.SensorData.DataMapEntry\x1a.\n\x0c\x44\x61taMapEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\x0c:\x02\x38\x01\"\x94\x02\n\x07IMUData\x12#\n\x05gyros\x18\x01 \x03(\x0b\x32\x14.Protos.IMUData.gyro\x12!\n\x04mags\x18\x02 \x03(\x0b\x32\x13.Protos.IMUData.mag\x12!\n\x04\x61\x63\x63s\x18\x03 \x03(\x0b\x32\x13.Protos.IMUData.acc\x1a\x36\n\x04gyro\x12\x0e\n\x06gyro_x\x18\x01 \x01(\x02\x12\x0e\n\x06gyro_y\x18\x02 \x01(\x02\x12\x0e\n\x06gyro_z\x18\x03 \x01(\x02\x1a\x32\n\x03mag\x12\r\n\x05mag_x\x18\x01 \x01(\x02\x12\r\n\x05mag_y\x18\x02 \x01(\x02\x12\r\n\x05mag_z\x18\x03 \x01(\x02\x1a\x32\n\x03\x61\x63\x63\x12\r\n\x05\x61\x63\x63_x\x18\x01 \x01(\x02\x12\r\n\x05\x61\x63\x63_y\x18\x02 \x01(\x02\x12\r\n\x05\x61\x63\x63_z\x18\x03 \x01(\x02\"\xb9\x01\n\x07PPGData\x12!\n\x04leds\x18\x01 \x03(\x0b\x32\x13.Protos.PPGData.led\x12\x31\n\x0ctemperatures\x18\x02 \x03(\x0b\x32\x1b.Protos.PPGData.temperature\x1a\x32\n\x03led\x12\r\n\x05led_1\x18\x01 \x01(\x05\x12\r\n\x05led_2\x18\x02 \x01(\x05\x12\r\n\x05led_3\x18\x03 \x01(\x05\x1a$\n\x0btemperature\x12\x15\n\rtemperature_1\x18\x01 \x01(\x02\x62\x06proto3')

_globals = globals()
_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, _globals)
_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'sensor_data_pb2', _globals)
if not _descriptor._USE_C_DESCRIPTORS:
  DESCRIPTOR._loaded_options = None
  _globals['_SENSORDATA_DATAMAPENTRY']._loaded_options = None
  _globals['_SENSORDATA_DATAMAPENTRY']._serialized_options = b'8\001'
  _globals['_SENSORDATA']._serialized_start=30
  _globals['_SENSORDATA']._serialized_end=205
  _globals['_SENSORDATA_DATAMAPENTRY']._serialized_start=159
  _globals['_SENSORDATA_DATAMAPENTRY']._serialized_end=205
  _globals['_IMUDATA']._serialized_start=208
  _globals['_IMUDATA']._serialized_end=484
  _globals['_IMUDATA_GYRO']._serialized_start=326
  _globals['_IMUDATA_GYRO']._serialized_end=380
  _globals['_IMUDATA_MAG']._serialized_start=382
  _globals['_IMUDATA_MAG']._serialized_end=432
  _globals['_IMUDATA_ACC']._serialized_start=434
  _globals['_IMUDATA_ACC']._serialized_end=484
  _globals['_PPGDATA']._serialized_start=487
  _globals['_PPGDATA']._serialized_end=672
  _globals['_PPGDATA_LED']._serialized_start=584
  _globals['_PPGDATA_LED']._serialized_end=634
  _globals['_PPGDATA_TEMPERATURE']._serialized_start=636
  _globals['_PPGDATA_TEMPERATURE']._serialized_end=672
# @@protoc_insertion_point(module_scope)

# --- End of sensor_data_pb2.py ---


# --- Start of simulator.py ---
import json
from topic import Topic
from data_classes import BrokerSettings, ClientSettings

class Simulator:
    def __init__(self, settings_file):
        self.default_client_settings = ClientSettings(
            clean=True,
            retain=False,
            qos=2,
            time_interval=5
        )
        self.settings_file = settings_file
        self.topics = []

    def read_client_settings(self, settings_dict: dict, default: ClientSettings):
        return ClientSettings(
            clean=settings_dict.get('CLEAN_SESSION', default.clean),
            retain=settings_dict.get('RETAIN', default.retain),
            qos=settings_dict.get('QOS', default.qos),
            time_interval=settings_dict.get('TIME_INTERVAL', default.time_interval)
        )

    def load_topics(self):
        topics = []
        with open(self.settings_file) as json_file:
            config = json.load(json_file)
            broker_settings = BrokerSettings(
                url=config.get('BROKER_URL', 'localhost'),
                port=config.get('BROKER_PORT', 1883),
                protocol=config.get('PROTOCOL_VERSION', 4)
            )
            broker_client_settings = self.read_client_settings(config, default=self.default_client_settings)
            for topic in config['TOPICS']:
                topic_data = topic['DATA']
                topic_payload_root = topic.get('PAYLOAD_ROOT', {})
                topic_client_settings = self.read_client_settings(topic, default=broker_client_settings)
                if topic['TYPE'] == 'list':
                    for item in topic['LIST']:
                        topic_url = topic['PREFIX'] + '/' + str(item)
                        topics.append(Topic(broker_settings, topic_url, topic_data, topic_payload_root, topic_client_settings))
        self.topics = topics

    def run(self):
        self.load_topics()  # Load topics to initialize threads
        while True:
            # Start each topic thread
            for topic in self.topics:
                if not topic.is_alive():  # Check if thread is not running
                    print(f'Starting: {topic.topic_url} ...')
                    topic.start()

            # Join threads to wait for their completion
            for topic in self.topics:
                topic.join()

# --- End of simulator.py ---


# --- Start of topic.py ---
import random
import time
import threading
import struct
import sensor_data_pb2  # Import the compiled Protobuf definitions
import paho.mqtt.client as mqtt
from data_classes import BrokerSettings, ClientSettings
from topic_data import TopicDataNumber, TopicDataBool, TopicDataRawValue, TopicDataMathExpression

class Topic(threading.Thread):
    def __init__(self, broker_settings: BrokerSettings, topic_url: str, topic_data: list, topic_payload_root: dict, client_settings: ClientSettings):
        threading.Thread.__init__(self)
        self.broker_settings = broker_settings
        self.topic_url = topic_url
        self.topic_data = self.load_topic_data(topic_data)
        self.topic_payload_root = topic_payload_root
        self.client_settings = client_settings
        self.loop = False
        self.client = None
        self.payload = None

    def load_topic_data(self, topic_data_object):
        topic_data = []
        for data in topic_data_object:
            data_type = data['TYPE']
            if data_type == 'int' or data_type == 'float':
                topic_data.append(TopicDataNumber(data))
            elif data_type == 'bool':
                topic_data.append(TopicDataBool(data))
            elif data_type == 'raw_values':
                topic_data.append(TopicDataRawValue(data))
            elif data_type == 'math_expression':
                topic_data.append(TopicDataMathExpression(data))
            else:
                raise NameError(f"Data TYPE '{data_type}' is unknown")
        return topic_data

    def connect(self):
        self.loop = True
        clean_session = None if self.broker_settings.protocol == mqtt.MQTTv5 else self.client_settings.clean
        self.client = mqtt.Client(self.topic_url, protocol=self.broker_settings.protocol, clean_session=clean_session)
        self.client.on_publish = self.on_publish
        self.client.connect(self.broker_settings.url, self.broker_settings.port)
        self.client.loop_start()

    def disconnect(self):
        self.loop = False
        if self.client:
            self.client.loop_stop()
            self.client.disconnect()

    def run(self):
        self.connect()
        while self.loop:
            try:
                # Generate Protobuf payload and publish it
                self.payload = self.generate_protobuf_payload()
                self.client.publish(topic=self.topic_url, payload=self.payload, qos=self.client_settings.qos, retain=self.client_settings.retain)
                
                # Delay between publishes based on time_interval
                time.sleep(self.client_settings.time_interval)

            except (mqtt.MQTTException, ConnectionError) as e:
                print(f"Connection error on topic {self.topic_url}: {e}. Attempting to reconnect...")
                time.sleep(5)
                self.connect()

    def on_publish(self, client, userdata, result):
        payload_str = ', '.join(f"{key}={value}" for key, value in self.payload_readable.items())
        print(f"[{time.strftime('%H:%M:%S')}] Data published on: {self.topic_url} {payload_str}")


    def generate_protobuf_payload(self):
        # Create a SensorData Protobuf message
        sensor_data = sensor_data_pb2.SensorData()
        sensor_data.pacifier_id = self.extract_pacifier_id(self.topic_url)
        sensor_data.sensor_type = self.extract_sensor_type(self.topic_url)
        sensor_data.sensor_group = self.extract_sensor_group(self.topic_url)

        # Initialize a dictionary to hold the payload data for logging
        data_dict = {}

        # Populate data_map based on the topic type
        if "ppg" in self.topic_url:
            sensor_data.data_map["led_1"] = struct.pack("i", random.randint(100, 110))
            data_dict["led_1"] = random.randint(100, 110)
            sensor_data.data_map["led_2"] = struct.pack("i", random.randint(100, 110))
            data_dict["led_2"] = random.randint(100, 110)
            sensor_data.data_map["led_3"] = struct.pack("i", random.randint(100, 110))
            data_dict["led_3"] = random.randint(100, 110)
            sensor_data.data_map["temperature"] = struct.pack("f", round(random.uniform(36.5, 37.5), 1))
            data_dict["temperature"] = round(random.uniform(36.5, 37.5), 1)

        elif "imu" in self.topic_url:
            sensor_data.data_map["acc_x"] = struct.pack("f", round(random.uniform(-0.03, 0.03), 2))
            data_dict["acc_x"] = round(random.uniform(-0.03, 0.03), 2)
            sensor_data.data_map["acc_y"] = struct.pack("f", round(random.uniform(-0.03, 0.03), 2))
            data_dict["acc_y"] = round(random.uniform(-0.03, 0.03), 2)
            sensor_data.data_map["acc_z"] = struct.pack("f", round(random.uniform(-0.03, 0.03), 2))
            data_dict["acc_z"] = round(random.uniform(-0.03, 0.03), 2)
            sensor_data.data_map["gyro_x"] = struct.pack("f", round(random.uniform(-0.2, 0.2), 2))
            data_dict["gyro_x"] = round(random.uniform(-0.2, 0.2), 2)
            sensor_data.data_map["gyro_y"] = struct.pack("f", round(random.uniform(-0.2, 0.2), 2))
            data_dict["gyro_y"] = round(random.uniform(-0.2, 0.2), 2)
            sensor_data.data_map["gyro_z"] = struct.pack("f", round(random.uniform(-0.2, 0.2), 2))
            data_dict["gyro_z"] = round(random.uniform(-0.2, 0.2), 2)
            sensor_data.data_map["mag_x"] = struct.pack("f", round(random.uniform(-0.05, 0.05), 2))
            data_dict["mag_x"] = round(random.uniform(-0.05, 0.05), 2)
            sensor_data.data_map["mag_y"] = struct.pack("f", round(random.uniform(-0.05, 0.05), 2))
            data_dict["mag_y"] = round(random.uniform(-0.05, 0.05), 2)
            sensor_data.data_map["mag_z"] = struct.pack("f", round(random.uniform(-0.05, 0.05), 2))
            data_dict["mag_z"] = round(random.uniform(-0.05, 0.05), 2)

        # Save data_dict for logging in the on_publish method
        self.payload_readable = data_dict

        # Serialize the Protobuf message
        return sensor_data.SerializeToString()


    def extract_pacifier_id(self, topic_url):
        return topic_url.split('/')[1]

    def extract_sensor_type(self, topic_url):
        return topic_url.split('/')[-1]

    def extract_sensor_group(self, topic_url):
        return "default_group"

# --- End of topic.py ---


# --- Start of utils.py ---
import random

def should_run_with_probability(probability: float):
    random_number = random.random()
    return random_number < probability

# --- End of utils.py ---


# --- Start of broker_settings.py ---
from dataclasses import dataclass

@dataclass
class BrokerSettings:
    url: str
    port: int
    protocol: int

# --- End of broker_settings.py ---


# --- Start of client_settings.py ---
from dataclasses import dataclass

@dataclass
class ClientSettings:
    clean: bool
    retain: bool
    qos: int
    time_interval: int

# --- End of client_settings.py ---


# --- Start of __init__.py ---
from .broker_settings import *
from .client_settings import *

# --- End of __init__.py ---


# --- Start of topic_data.py ---
from abc import ABC, abstractmethod
from utils import should_run_with_probability

class TopicData(ABC):
    def __init__(self, data):
        self.data = data
        self.name = data['NAME']
        self.is_active = True
        self.old_value = None

    def generate_value(self):
        new_value = None
        if self.old_value is None:
            # generate initial data
            if 'INITIAL_VALUE' in self.data:
                new_value = self.data['INITIAL_VALUE']
            else:
                new_value = self.generate_initial_value()
        else:
            # generate next data
            if should_run_with_probability(self.data.get('RETAIN_PROBABILITY', 0)):
                new_value = self.old_value
            elif should_run_with_probability(self.data.get('RESET_PROBABILITY', 0)):
                new_value = self.generate_initial_value()
            else:
                new_value = self.generate_next_value()
        self.old_value = new_value
        return new_value

    @abstractmethod
    def generate_initial_value(self):
        pass

    @abstractmethod
    def generate_next_value(self):
        pass

# --- End of topic_data.py ---


# --- Start of topic_data_bool.py ---
import random
from .topic_data import TopicData

class TopicDataBool(TopicData):
    def __init__(self, data):
        super().__init__(data)

    def generate_initial_value(self):
        return random.choice([True, False])

    def generate_next_value(self):
        return not self.old_value # can be kept the same according to RETAIN_PROBABILITY

# --- End of topic_data_bool.py ---


# --- Start of topic_data_math_expression.py ---
import math
import random
from .topic_data import TopicData

class TopicDataMathExpression(TopicData):
    def __init__(self, data):
        super().__init__(data)
        self.expression_evaluator = None

    def generate_initial_value(self):
        self.expression_evaluator = ExpressionEvaluator(self.data['MATH_EXPRESSION'], self.data['INTERVAL_START'], self.data['INTERVAL_END'], self.data['MIN_DELTA'], self.data['MAX_DELTA'])
        return self.expression_evaluator.get_current_expression_value()

    def generate_next_value(self):
        return self.expression_evaluator.get_next_expression_value()


class ExpressionEvaluator():
    def __init__(self, math_expression, interval_start, interval_end, min_delta, max_delta):
        self._math_expression = self.generate_compiled_expression(math_expression)
        self._interval_start = interval_start
        self._interval_end = interval_end
        self._min_delta = min_delta
        self._max_delta = max_delta
        self._x = interval_start

    def get_current_expression_value(self):
        return self._math_expression(self._x)

    def get_next_expression_value(self):
        if self._x > self._interval_end:
            self._x = self._interval_start
            return self.get_current_expression_value()
        step = random.uniform(self._min_delta, self._max_delta)
        self._x += step
        return self.get_current_expression_value()

    def generate_compiled_expression(self, expression):
        lambda_expression = "lambda x: "+expression
        code = compile(lambda_expression, "<string>", "eval")
        ALLOWED_FUNCTIONS = {function_name: func for function_name, func in math.__dict__.items() if not function_name.startswith("__")}
        for name in code.co_names:
            if name not in ALLOWED_FUNCTIONS:
                raise NameError(f"The use of '{name}' is not allowed")
        return eval(code, {"__builtins__": {}, "math":math}, ALLOWED_FUNCTIONS)

# --- End of topic_data_math_expression.py ---


# --- Start of topic_data_number.py ---
import random
from .topic_data import TopicData
from utils import should_run_with_probability

class TopicDataNumber(TopicData):
    def __init__(self, data):
        super().__init__(data)
        self.is_int = data['TYPE'] == 'int'

    def generate_initial_value(self):
        if self.is_int:
            # int number
            return random.randint(self.data['MIN_VALUE'], self.data['MAX_VALUE'])
        else:
            # float number
            return random.uniform(self.data['MIN_VALUE'], self.data['MAX_VALUE'])

    def generate_next_value(self):
        if self.data.get('RESTART_ON_BOUNDARIES', False) and (self.old_value == self.data.get('MIN_VALUE') or self.old_value == self.data.get('MAX_VALUE')):
            return self.generate_initial_value()
        step = random.uniform(0, self.data['MAX_STEP'])
        step = round(step) if self.is_int else step
        increase_probability = self.data['INCREASE_PROBABILITY'] if 'INCREASE_PROBABILITY' in self.data else 0.5
        if should_run_with_probability(1 - increase_probability):
            step *= -1
        return max(self.old_value + step, self.data['MIN_VALUE']) if step < 0 else min(self.old_value + step, self.data['MAX_VALUE'])

# --- End of topic_data_number.py ---


# --- Start of topic_data_raw_value.py ---
# topic_data_raw_value.py
from .topic_data import TopicData

class TopicDataRawValue(TopicData):
    def __init__(self, data):
        super().__init__(data)
        self.raw_values_index = 0

    def generate_initial_value(self):
        self.raw_values_index = self.data.get('INDEX_START', 0)
        return self.get_current_value()

    def generate_next_value(self):
        end_index = self.data.get('INDEX_END', len(self.data['VALUES']) - 1)
        self.raw_values_index += 1
        if self.raw_values_index <= end_index:
            return self.get_current_value()
        elif self.raw_values_index > end_index and self.data.get('RESTART_ON_END', False):
            self.raw_values_index = self.data.get('INDEX_START', 0)
            return self.generate_initial_value()
        else:
            self.is_active = False

    def get_current_value(self):
        current_value_for_index = self.data['VALUES'][self.raw_values_index]
        if 'VALUE_DEFAULT' in self.data:
            value = {}
            value.update(self.data.get('VALUE_DEFAULT', {}))
            value.update(current_value_for_index)
            return value
        return current_value_for_index

# --- End of topic_data_raw_value.py ---


# --- Start of __init__.py ---
from .topic_data_number import TopicDataNumber
from .topic_data_bool import TopicDataBool
from .topic_data_raw_value import TopicDataRawValue
from .topic_data_math_expression import TopicDataMathExpression

# --- End of __init__.py ---

